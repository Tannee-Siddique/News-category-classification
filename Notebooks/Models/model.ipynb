{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import pipeline\n",
    "from pymongo import MongoClient\n",
    "import pandas as pd\n",
    "import json\n",
    "import urllib.parse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load credentials from JSON file\n",
    "with open('credentials_mongodb.json') as f:\n",
    "    login = json.load(f)\n",
    "\n",
    "# Assign credentials to variables\n",
    "username = login['username']\n",
    "password = urllib.parse.quote(login['password'])  # Ensure the password is URL encoded\n",
    "host = login['host']\n",
    "\n",
    "# Construct the MongoDB connection string\n",
    "url = f\"mongodb+srv://{username}:{password}@{host}/?retryWrites=true&w=majority\"\n",
    "\n",
    "# MongoDB setup\n",
    "client = MongoClient(url)  # Use the constructed connection string\n",
    "db = client['news_database']  # Replace with your database name\n",
    "collection = db['news_collection']  # Replace with your collection name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fetch all documents from the MongoDB collection\n",
    "#articles = list(collection.find())\n",
    "# Fetch a limited number of documents from MongoDB (e.g., 100 documents)\n",
    "subset_size = 5  # Adjust this number based on the subset size you want\n",
    "articles = list(collection.find().limit(subset_size))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert to a pandas DataFrame\n",
    "df = pd.DataFrame(articles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 2: Define possible writing styles for classification\n",
    "writing_styles = [\"expository\", \"narrative\", \"descriptive\", \"persuasive\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import pipeline\n",
    "\n",
    "# Check if GPU is available\n",
    "device = 0 if torch.cuda.is_available() else -1\n",
    "\n",
    "# Initialize the zero-shot classifier pipeline and use GPU if available\n",
    "classifier = pipeline(\"zero-shot-classification\", model=\"facebook/bart-large-mnli\", device=device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 3: Perform zero-shot classification on the headlines or short descriptions\n",
    "df['detected_writing_style'] = df['headline'].apply(lambda x: classifier(x, candidate_labels=writing_styles)['labels'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                            headline detected_writing_style\n",
      "0  Over 4 Million Americans Roll Up Sleeves For O...             persuasive\n",
      "1  American Airlines Flyer Charged, Banned For Li...             persuasive\n",
      "2  23 Of The Funniest Tweets About Cats And Dogs ...             persuasive\n",
      "3  The Funniest Tweets From Parents This Week (Se...             persuasive\n",
      "4  Woman Who Called Cops On Black Bird-Watcher Lo...            descriptive\n"
     ]
    }
   ],
   "source": [
    "# Step 4: Display the dataset with detected writing styles\n",
    "print(df[['headline', 'detected_writing_style']].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "InsertManyResult([ObjectId('6706b7e97424b08e25a00d5a'), ObjectId('6706b7e97424b08e25a00d5b'), ObjectId('6706b7e97424b08e25a00d5c'), ObjectId('6706b7e97424b08e25a00d5d'), ObjectId('6706b7e97424b08e25a00d5e')], acknowledged=True)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Step 5: (Optional) Save the auto-labeled dataset back to MongoDB\n",
    "collection_with_styles = db['news_articles_with_styles']  # New collection to store the auto-labeled data\n",
    "collection_with_styles.insert_many(df.to_dict('records'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "adsc_3610",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
